{
  "artifacts": [],
  "command": "my_main",
  "experiment": {
    "base_dir": "C:\\Users\\hsk\\Desktop\\python\\pymarl",
    "dependencies": [
      "numpy==1.23.1",
      "PyYAML==6.0.2",
      "sacred==0.8.7",
      "torch==1.13.1+cu117"
    ],
    "mainfile": "main.py",
    "name": "pymarl",
    "repositories": [
      {
        "commit": "546d05317fef9d830c7071d58882d21aefa8b00b",
        "dirty": true,
        "url": "https://github.com/Kai05012002/testpymarl.git"
      },
      {
        "commit": "546d05317fef9d830c7071d58882d21aefa8b00b",
        "dirty": true,
        "url": "https://github.com/Kai05012002/testpymarl.git"
      },
      {
        "commit": "546d05317fef9d830c7071d58882d21aefa8b00b",
        "dirty": true,
        "url": "https://github.com/Kai05012002/testpymarl.git"
      }
    ],
    "sources": [
      [
        "main.py",
        "_sources\\main_319c15f2fb11d58696da491439d5dbb5.py"
      ],
      [
        "run.py",
        "_sources\\run_3d13dbdeea410bcf5bb87beb4266819c.py"
      ],
      [
        "utils\\logging.py",
        "_sources\\logging_1c1c5c83be7ac7b7b69888b3bcb127e3.py"
      ]
    ]
  },
  "fail_trace": [
    "Traceback (most recent call last):\n",
    "  File \"C:\\Users\\hsk\\anaconda3\\envs\\SMAC0104\\lib\\site-packages\\sacred\\config\\captured_function.py\", line 42, in captured_function\n    result = wrapped(*args, **kwargs)\n",
    "  File \"C:\\Users\\hsk\\Desktop\\python\\pymarl\\main.py\", line 36, in my_main\n    run(_run, config, _log)\n",
    "  File \"C:\\Users\\hsk\\Desktop\\python\\pymarl\\run.py\", line 51, in run\n    run_sequential(args=args, logger=logger)\n",
    "  File \"C:\\Users\\hsk\\Desktop\\python\\pymarl\\run.py\", line 210, in run_sequential\n    episode_batch = runner.run(test_mode=False)\n",
    "  File \"C:\\Users\\hsk\\Desktop\\python\\pymarl\\runners\\episode_runner.py\", line 67, in run\n    self.batch.update(pre_transition_data, ts=self.t)\n",
    "  File \"C:\\Users\\hsk\\Desktop\\python\\pymarl\\components\\episode_buffer.py\", line 108, in update\n    self._check_safe_view(v, target[k][_slices])\n",
    "  File \"C:\\Users\\hsk\\Desktop\\python\\pymarl\\components\\episode_buffer.py\", line 123, in _check_safe_view\n    raise ValueError(\"Unsafe reshape of {} to {}\".format(v.shape, dest.shape))\n",
    "ValueError: Unsafe reshape of torch.Size([1, 54]) to torch.Size([1, 1, 21])\n"
  ],
  "heartbeat": "2025-01-04T18:50:32.233581",
  "host": {
    "ENV": {},
    "cpu": "Intel(R) Core(TM) i5-14500",
    "gpus": {
      "driver_version": "566.03",
      "gpus": [
        {
          "model": "NVIDIA GeForce RTX 4070 Ti SUPER",
          "persistence_mode": false,
          "total_memory": 16376
        }
      ]
    },
    "hostname": "DESKTOP-68E0S8K",
    "os": [
      "Windows",
      "Windows-10-10.0.19045-SP0"
    ],
    "python_version": "3.10.14"
  },
  "meta": {
    "command": "my_main",
    "config_updates": {
      "use_cuda": true
    },
    "named_configs": [],
    "options": {
      "--beat-interval": null,
      "--capture": null,
      "--comment": null,
      "--debug": false,
      "--enforce_clean": false,
      "--file_storage": null,
      "--force": false,
      "--help": false,
      "--id": null,
      "--loglevel": null,
      "--mongo_db": null,
      "--name": null,
      "--pdb": false,
      "--print-config": false,
      "--priority": null,
      "--queue": false,
      "--s3": null,
      "--sql": null,
      "--tiny_db": null,
      "--unobserved": false,
      "COMMAND": null,
      "UPDATE": [
        "use_cuda=True"
      ],
      "help": false,
      "with": true
    }
  },
  "resources": [],
  "result": null,
  "start_time": "2025-01-04T18:50:24.538666",
  "status": "FAILED",
  "stop_time": "2025-01-04T18:50:32.235582"
}